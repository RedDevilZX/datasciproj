import pandas as pd

import numpy as np

import matplotlib.pyplot as plt

import seaborn as sns

from sklearn.model_selection import train_test_split

from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder

from sklearn.ensemble import RandomForestClassifier

from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

from sklearn.pipeline import Pipeline

from sklearn.compose import ColumnTransformer

# Load the dataset

data = pd.read_excel('Patient_Data.xlsx')

# Data Preprocessing

# Expand the dataset to include additional factors such as demographics, clinical biomarkers, medication history, etc.

# Feature Engineering

# Include additional features based on demographic information, clinical biomarkers, medication history, etc.

# Model Training

# Define features (X) and target variable (y)

X = data.drop(columns=['Name']) # Update columns based on expanded dataset

y = data['Name']

# Split the data into training and testing sets

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Define numeric and categorical features

numeric_features = X.select_dtypes(include=np.number).columns

categorical_features = X.select_dtypes(include=object).columns

# Preprocessing pipeline for numeric features

numeric_transformer = Pipeline(steps=[

('scaler', StandardScaler())

])

# Preprocessing pipeline for categorical features

categorical_transformer = Pipeline(steps=[

('onehot', OneHotEncoder(handle_unknown='ignore'))

])

# Column transformer to apply different preprocessing steps to numeric and categorical features

preprocessor = ColumnTransformer(

transformers=[

('num', numeric_transformer, numeric_features),

('cat', categorical_transformer, categorical_features)

])

# Model pipeline

pipeline = Pipeline([

('preprocessor', preprocessor),

('classifier', RandomForestClassifier())

])

# Train the model

pipeline.fit(X_train, y_train)

# Model Evaluation

# Predict on the testing set

y_pred = pipeline.predict(X_test)

# Evaluate model performance

accuracy = accuracy_score(y_test, y_pred)

print("Accuracy:", accuracy)

# Classification report

print(classification_report(y_test, y_pred, zero_division=1))

# Confusion matrix

conf_matrix = confusion_matrix(y_test, y_pred)

sns.heatmap(conf_matrix, annot=True, cmap="YlGnBu", fmt="d")

plt.xlabel('Predicted')

plt.ylabel('Actual')

plt.title('Confusion Matrix')

plt.show()

# Plot feature importance

importances = pipeline.named_steps['classifier'].feature_importances_

# Get feature names after one-hot encoding

cat_encoder = pipeline.named_steps['preprocessor'].named_transformers_['cat'].named_steps['onehot']

cat_onehot_features = list(cat_encoder.get_feature_names_out(categorical_features))

all_features = list(numeric_features) + cat_onehot_features

indices = np.argsort(importances)

plt.figure(figsize=(10, 6))

plt.title('Feature Importances')

plt.barh(range(len(indices)), importances[indices], color='b', align='center')

plt.yticks(range(len(indices)), [all_features[i] for i in indices])

plt.xlabel('Relative Importance')

plt.show()

# Plot correlation matrix

corr_matrix = data.corr()

plt.figure(figsize=(12, 8))

sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f")

plt.title('Correlation Matrix')

plt.show()

# Check if selected features exist in the dataset

selected_features = ['Age', 'BMI', 'Blood_Pressure', 'Cholesterol']

valid_selected_features = [feature for feature in selected_features if feature in data.columns]

# Pairplot for selected features

if valid_selected_features:

sns.pairplot(data[valid_selected_features])

plt.title('Pairplot of Selected Features')

plt.show()

else:

print("Selected features not found in the dataset.")